{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f86df7",
   "metadata": {},
   "source": [
    "# Run all chromosomes without Bottleneck - maximum recon?\n",
    "\n",
    "- Read in best model from fine-grained\n",
    "- Rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc81fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle \n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e1c1af",
   "metadata": {},
   "source": [
    "# Find best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7750d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_data = \"/data/scratch/skatz/PROJECTS/methylnet/1_healthyVAE/data/GSE87571/train_val_test_sets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a22a9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for CHR in [f\"chr{i}\" for i in range(1,23)]:\n",
    "    PATH_results = f\"logs/finalModels/{CHR}/noBottleneck\"\n",
    "    os.makedirs(PATH_results, exist_ok=True)\n",
    "    param_grid = dict()\n",
    "\n",
    "    ### Step 1: read in old model\n",
    "    ## a. original parameters\n",
    "    with open(f\"logs/optimisation/{CHR}/fine/param_grid_fine.json\", \"r\") as f: dict_oldGrid = json.load(f)\n",
    "    ## b. best HP model\n",
    "    with open(f\"logs/optimisation/{CHR}/fine/best_model_fineOptimization.json\", \"r\") as f: dict_bestModel = json.load(f)\n",
    "\n",
    "    ### Step 3: design latSizes\n",
    "    with open(os.path.join(PATH_data, f\"{CHR}_train_methyl_array.pkl\"), \"rb\") as f: train_dataset = pickle.load(f) #\n",
    "    num_cpgs = train_dataset[\"beta\"].shape[1]\n",
    "    param_grid[\"latentSize\"] = num_cpgs\n",
    "    ### Step 4: get lr and dropout\n",
    "    param_grid[\"lr\"] = dict_bestModel[\"lr\"]\n",
    "    param_grid[\"dropout\"] = dict_bestModel[\"dropr\"]\n",
    "\n",
    "    ### Save parameter grid in file for later documentation\n",
    "    with open(f\"{PATH_results}/param_grid.json\", \"w\") as f: f.write(json.dumps(param_grid, indent=\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2665c1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote file \tlatSize_29482\n",
      "Wrote file \tlatSize_21984\n",
      "Wrote file \tlatSize_15547\n",
      "Wrote file \tlatSize_13100\n",
      "Wrote file \tlatSize_15965\n",
      "Wrote file \tlatSize_23070\n",
      "Wrote file \tlatSize_19599\n",
      "Wrote file \tlatSize_13704\n",
      "Wrote file \tlatSize_6619\n",
      "Wrote file \tlatSize_15736\n",
      "Wrote file \tlatSize_18570\n",
      "Wrote file \tlatSize_15165\n",
      "Wrote file \tlatSize_7802\n",
      "Wrote file \tlatSize_9417\n",
      "Wrote file \tlatSize_9715\n",
      "Wrote file \tlatSize_13823\n",
      "Wrote file \tlatSize_17044\n",
      "Wrote file \tlatSize_3654\n",
      "Wrote file \tlatSize_15475\n",
      "Wrote file \tlatSize_6567\n",
      "Wrote file \tlatSize_2719\n",
      "Wrote file \tlatSize_5243\n"
     ]
    }
   ],
   "source": [
    "for CHR in [f\"chr{i}\" for i in range(1,23)]:\n",
    "    PATH_results = f\"logs/finalModels/{CHR}/noBottleneck\"\n",
    "    ### Load parameter grid\n",
    "    with open(f\"{PATH_results}/param_grid.json\", \"r\") as f: param_grid_comb=json.loads(f.read())\n",
    "\n",
    "    ### Generate submit.sh with combinations\n",
    "    os.makedirs(f\"{PATH_results}/submit\", exist_ok=True)\n",
    "    with open(\"submit_template_noEncoder.sh\", \"r\") as f: template=f.read()             \n",
    "    latSize = str(param_grid_comb[\"latentSize\"])\n",
    "    lr = str(param_grid_comb[\"lr\"])\n",
    "    dropr = str(param_grid_comb[\"dropout\"])\n",
    "\n",
    "    ### Generate run name - combination of parameter settings\n",
    "    fileName = f\"latSize_{latSize}\"\n",
    "    ### Replace in template file\n",
    "    template_updated = template.replace(\"$PATH\", str(PATH_results+\"/\"+fileName)) \\\n",
    "                                   .replace(\"$CHR\",  str(CHR)) \\\n",
    "                                   .replace(\"$LATSIZE\", latSize) \\\n",
    "                                   .replace(\"$LR\", lr) \\\n",
    "                                   .replace(\"$DROPR\", dropr)\n",
    "    with open(f\"{PATH_results}/submit/{fileName}.sh\", \"w\") as f: f.write(template_updated)\n",
    "    print(f\"Wrote file \\t{fileName}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e5f018",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8893cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "def calc_r2(model, data_tensor):    \n",
    "    model.eval()\n",
    "    orig = data_tensor.cpu().detach().numpy()\n",
    "    recon = model(data_tensor)\n",
    "    # check if VAE or AE was used\n",
    "    if isinstance(recon, tuple):\n",
    "        recon = recon[0].cpu().detach().numpy()\n",
    "    else:\n",
    "        recon = recon.detach().numpy()\n",
    "    r2 = []\n",
    "    for i in range(recon.shape[1]):\n",
    "        r2.append(pearsonr(orig[:,i], recon[:,i])[0])\n",
    "    return np.array(r2).mean().round(3), np.array(r2).std().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fbc56eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1 0.64 0.183\n",
      "chr2 0.648 0.179\n",
      "chr3 0.671 0.17\n",
      "chr4 0.642 0.181\n",
      "chr5 0.638 0.181\n",
      "chr6 nan nan\n",
      "chr7 0.641 0.179\n",
      "chr8 0.646 0.177\n",
      "chr9 nan nan\n",
      "chr10 0.643 0.179\n",
      "chr11 0.656 0.173\n",
      "chr12 0.646 0.178\n",
      "chr13 nan nan\n",
      "chr14 0.653 0.177\n",
      "chr15 0.646 0.179\n",
      "chr16 0.643 0.174\n",
      "chr17 0.667 0.171\n",
      "chr18 0.677 0.176\n",
      "chr19 0.646 0.177\n",
      "chr20 nan nan\n",
      "chr21 0.687 0.169\n",
      "chr22 0.662 0.173\n"
     ]
    }
   ],
   "source": [
    "PATH_data = \"/data/scratch/skatz/PROJECTS/methylnet/1_healthyVAE/data/GSE87571/train_val_test_sets/\"\n",
    "\n",
    "all_mean = []\n",
    "all_std = []\n",
    "for CHR in [f\"chr{i}\" for i in range(1,23)]:\n",
    "    with open(os.path.join(PATH_data, f\"{CHR}_test_methyl_array.pkl\"), \"rb\") as f: test_dataset = pickle.load(f) #\n",
    "    test_tensor = torch.tensor(test_dataset[\"beta\"].values, dtype=torch.float32)\n",
    "    \n",
    "    PATH_results = f\"logs/finalModels/{CHR}/noBottleneck\"\n",
    "    with open(f\"{PATH_results}/param_grid.json\", \"r\") as f: dict_bestModel = json.load(f)\n",
    "    latSize = dict_bestModel[\"latentSize\"]\n",
    "    name = f\"latSize_{latSize}\"\n",
    "    path = f\"{PATH_results}/{name}\"\n",
    "    model = torch.load(f\"{path}/checkpoint/trainedModel.pth\", map_location=torch.device('cpu'))\n",
    "    \n",
    "    mean, std = calc_r2(model, test_tensor)\n",
    "    print(CHR, mean, std)\n",
    "    all_mean.append(mean)\n",
    "    all_std.append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5339483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.652888888888889\n",
      "0.17644444444444443\n"
     ]
    }
   ],
   "source": [
    "print(np.nanmean(np.array(all_mean)))\n",
    "print(np.nanmean(np.array(all_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5ad41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
